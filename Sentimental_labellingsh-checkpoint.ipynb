{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xt_8-C-4kdzb"
   },
   "source": [
    "# **PROJECT:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUWVtpVIkoKN"
   },
   "source": [
    "# **Analyzing Sentimental Change Across Music Eras**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "is2ujdM8ktqX"
   },
   "source": [
    "## **Roll numbers:**\n",
    "1. Hamza Khan(21l-5654)\n",
    "\n",
    "2. Shahzeb Faisal(21l-5649)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7JJxM1VUlPGC"
   },
   "source": [
    "# **PROCESS:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RCLKbB7Mlfb7"
   },
   "source": [
    "# **Logistic regression as model**\n",
    "\n",
    "1. \"Sentiment Analyzer\"\n",
    "\n",
    "2. \"Bigram _feature_selection 1\"\n",
    "\n",
    "3. \"Bag of words _feature_selection 2\"\n",
    "\n",
    "4. \"TF-IDF _feature_selection 3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCrQcMHtlyxy"
   },
   "source": [
    "# **LIBRARIES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UgzgUt4Ll1fi"
   },
   "source": [
    "1. Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XvBCQWuch2qK",
    "outputId": "fac215d6-2fbc-4cc1-e288-dcec43cac207"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Hamza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Hamza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Hamza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Hamza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Hamza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langdetect in c:\\users\\hamza\\appdata\\roaming\\python\\python39\\site-packages (1.0.9)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from langdetect) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\hamza\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\hamza\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\hamza\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\hamza\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# Downloads\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('omw-1.4')\n",
    "!pip install langdetect\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4l1-lGerl6d4"
   },
   "source": [
    "2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xPAWxY8PiJ1b"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from langdetect import detect\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdqkPiSPmBKr"
   },
   "source": [
    "# **Reading csv files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t45PVihIiNI0",
    "outputId": "ab65df78-f0ff-49ff-ccb0-7e15cf742b50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1006 entries, 0 to 1005\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   Song_title           1006 non-null   object\n",
      " 1   Release_year         1006 non-null   int64 \n",
      " 2   Duration_in_seconds  1006 non-null   int64 \n",
      " 3   artist_name          1006 non-null   object\n",
      " 4   Playlist_name        1006 non-null   object\n",
      " 5   processed_lyrics     1006 non-null   object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 47.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Reading csv files\n",
    "original_data = pd.read_csv('processed_data.csv')\n",
    "original_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "id": "t-71O3pemFfo",
    "outputId": "c3b48fa5-ff73-4390-eddf-5cc2ee64c1e6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-8214e17a-9be7-4ea5-a7f5-98a640466609\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_title</th>\n",
       "      <th>Release_year</th>\n",
       "      <th>Duration_in_seconds</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>Playlist_name</th>\n",
       "      <th>processed_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lovin On Me</td>\n",
       "      <td>2023</td>\n",
       "      <td>138</td>\n",
       "      <td>Jack Harlow</td>\n",
       "      <td>Today’s Top Hits</td>\n",
       "      <td>like whips chains tie whip lovin baby whip lov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>greedy</td>\n",
       "      <td>2023</td>\n",
       "      <td>131</td>\n",
       "      <td>Tate McRae</td>\n",
       "      <td>Today’s Top Hits</td>\n",
       "      <td>​greedy said serious tried figure next night s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agora Hills</td>\n",
       "      <td>2023</td>\n",
       "      <td>265</td>\n",
       "      <td>Doja Cat</td>\n",
       "      <td>Today’s Top Hits</td>\n",
       "      <td>hills kissin hope caught us whether like show ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Houdini</td>\n",
       "      <td>2023</td>\n",
       "      <td>185</td>\n",
       "      <td>Dua Lipa</td>\n",
       "      <td>Today’s Top Hits</td>\n",
       "      <td>okay come go tell ways need long catch go houd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Strangers</td>\n",
       "      <td>2023</td>\n",
       "      <td>172</td>\n",
       "      <td>Kenya Grace</td>\n",
       "      <td>Today’s Top Hits</td>\n",
       "      <td>always ends every time meet somebody new like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>We Ride</td>\n",
       "      <td>2023</td>\n",
       "      <td>188</td>\n",
       "      <td>Bryan Martin</td>\n",
       "      <td>Chillin' on a Dirt Road</td>\n",
       "      <td>contributorswe ride well known write songs lov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>Out Of That Truck</td>\n",
       "      <td>2023</td>\n",
       "      <td>177</td>\n",
       "      <td>Carrie Underwood</td>\n",
       "      <td>Chillin' on a Dirt Road</td>\n",
       "      <td>contributorsout truck bet shotgun headrest sti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>Man! I Feel Like A Woman!</td>\n",
       "      <td>1997</td>\n",
       "      <td>234</td>\n",
       "      <td>Shania Twain</td>\n",
       "      <td>90s Country</td>\n",
       "      <td>37 contributorsman feel like woman lets go gir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>Sweet Home Alabama</td>\n",
       "      <td>1974</td>\n",
       "      <td>283</td>\n",
       "      <td>Lynyrd Skynyrd</td>\n",
       "      <td>Southern Rock</td>\n",
       "      <td>129 contributorssweet home alabama one two thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>Hard To Handle</td>\n",
       "      <td>1990</td>\n",
       "      <td>188</td>\n",
       "      <td>The Black Crowes</td>\n",
       "      <td>Southern Rock</td>\n",
       "      <td>30 contributorshard handle baby man scene give...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1006 rows × 6 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8214e17a-9be7-4ea5-a7f5-98a640466609')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-8214e17a-9be7-4ea5-a7f5-98a640466609 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-8214e17a-9be7-4ea5-a7f5-98a640466609');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-5afe892b-043b-4569-bd3f-41a9929631f7\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5afe892b-043b-4569-bd3f-41a9929631f7')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-5afe892b-043b-4569-bd3f-41a9929631f7 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                     Song_title  Release_year  Duration_in_seconds  \\\n",
       "0                   Lovin On Me          2023                  138   \n",
       "1                        greedy          2023                  131   \n",
       "2                   Agora Hills          2023                  265   \n",
       "3                       Houdini          2023                  185   \n",
       "4                     Strangers          2023                  172   \n",
       "...                         ...           ...                  ...   \n",
       "1001                    We Ride          2023                  188   \n",
       "1002          Out Of That Truck          2023                  177   \n",
       "1003  Man! I Feel Like A Woman!          1997                  234   \n",
       "1004         Sweet Home Alabama          1974                  283   \n",
       "1005             Hard To Handle          1990                  188   \n",
       "\n",
       "           artist_name            Playlist_name  \\\n",
       "0          Jack Harlow         Today’s Top Hits   \n",
       "1           Tate McRae         Today’s Top Hits   \n",
       "2             Doja Cat         Today’s Top Hits   \n",
       "3             Dua Lipa         Today’s Top Hits   \n",
       "4          Kenya Grace         Today’s Top Hits   \n",
       "...                ...                      ...   \n",
       "1001      Bryan Martin  Chillin' on a Dirt Road   \n",
       "1002  Carrie Underwood  Chillin' on a Dirt Road   \n",
       "1003      Shania Twain              90s Country   \n",
       "1004    Lynyrd Skynyrd            Southern Rock   \n",
       "1005  The Black Crowes            Southern Rock   \n",
       "\n",
       "                                       processed_lyrics  \n",
       "0     like whips chains tie whip lovin baby whip lov...  \n",
       "1     ​greedy said serious tried figure next night s...  \n",
       "2     hills kissin hope caught us whether like show ...  \n",
       "3     okay come go tell ways need long catch go houd...  \n",
       "4     always ends every time meet somebody new like ...  \n",
       "...                                                 ...  \n",
       "1001  contributorswe ride well known write songs lov...  \n",
       "1002  contributorsout truck bet shotgun headrest sti...  \n",
       "1003  37 contributorsman feel like woman lets go gir...  \n",
       "1004  129 contributorssweet home alabama one two thr...  \n",
       "1005  30 contributorshard handle baby man scene give...  \n",
       "\n",
       "[1006 rows x 6 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AswxxAMuiS1D",
    "outputId": "fed2c705-a9c7-4724-fdaf-9fe445e63155"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       like whips chains tie whip lovin baby whip lov...\n",
      "2       ​greedy said serious tried figure next night s...\n",
      "3       hills kissin hope caught us whether like show ...\n",
      "4       okay come go tell ways need long catch go houd...\n",
      "5       always ends every time meet somebody new like ...\n",
      "                              ...                        \n",
      "1002    contributorswe ride well known write songs lov...\n",
      "1003    contributorsout truck bet shotgun headrest sti...\n",
      "1004    37 contributorsman feel like woman lets go gir...\n",
      "1005    129 contributorssweet home alabama one two thr...\n",
      "1006    30 contributorshard handle baby man scene give...\n",
      "Name: Word, Length: 1006, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data_exploded = original_data['processed_lyrics'].explode().reset_index(drop=True)\n",
    "data_exploded = data_exploded.rename('Word')\n",
    "data_exploded = data_exploded.reset_index(drop=True)\n",
    "data_exploded.index = data_exploded.index + 1\n",
    "print(data_exploded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EowybmYgiTTl",
    "outputId": "cd2651ab-4c56-4db4-b4fd-61fdfbfd2ddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       like whips chains tie whip lovin baby whip lov...\n",
      "2       ​greedy said serious tried figure next night s...\n",
      "3       hills kissin hope caught us whether like show ...\n",
      "4       okay come go tell ways need long catch go houd...\n",
      "5       always ends every time meet somebody new like ...\n",
      "                              ...                        \n",
      "1002    contributorswe ride well known write songs lov...\n",
      "1003    contributorsout truck bet shotgun headrest sti...\n",
      "1004    37 contributorsman feel like woman lets go gir...\n",
      "1005    129 contributorssweet home alabama one two thr...\n",
      "1006    30 contributorshard handle baby man scene give...\n",
      "Name: Word, Length: 1006, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data_exploded = data_exploded.apply(str)\n",
    "word_series = data_exploded\n",
    "print(word_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8sf_715HmUUf"
   },
   "source": [
    "# **Sentiment analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7nOuDRLbiaDs",
    "outputId": "0b410221-1cd7-47ea-c240-ef52b9f4cbf5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Sentiment analysis\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cLl2-owAieJs"
   },
   "outputs": [],
   "source": [
    "def get_sentiment(word):\n",
    "    sentiment = sia.polarity_scores(word)\n",
    "    compound_score = sentiment['compound']\n",
    "    if compound_score >= 0.05:\n",
    "        return 'positive'\n",
    "    elif compound_score <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "word_series = pd.DataFrame(word_series, columns=['Word'])\n",
    "word_series['POS'] = word_series['Word'].apply(lambda word: nltk.pos_tag([word])[0][1])\n",
    "word_series['Sentiment'] = word_series['Word'].apply(get_sentiment)\n",
    "print(word_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "10lyPiaBilNG"
   },
   "outputs": [],
   "source": [
    "sentiment_counts = word_series['Sentiment'].value_counts()\n",
    "print(sentiment_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aVaKmr_vin6v"
   },
   "outputs": [],
   "source": [
    "# Plotting sentiment distribution\n",
    "plt.bar(sentiment_counts.index, sentiment_counts.values, color=['green', 'red', 'gray'])\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Number of Songs')\n",
    "plt.title('Number of Songs by Sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vdqAP9QwmiYz"
   },
   "source": [
    "# **Handling duplicates and unique words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "04AbFDAQitvu"
   },
   "outputs": [],
   "source": [
    "# Handling duplicates and unique words\n",
    "positive_duplicates = word_series[word_series['Sentiment'] == 'positive']['Word'].duplicated().sum()\n",
    "print(\"Duplicate words in Positive sentiment:\", positive_duplicates)\n",
    "negative_duplicates = word_series[word_series['Sentiment'] == 'negative']['Word'].duplicated().sum()\n",
    "print(\"Duplicate words in Negative sentiment:\", negative_duplicates)\n",
    "neutral_duplicates = word_series[word_series['Sentiment'] == 'neutral']['Word'].duplicated().sum()\n",
    "print(\"Duplicate words in Neutral sentiment:\", neutral_duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BKP3LMf4iyfP"
   },
   "outputs": [],
   "source": [
    "positive_unique_words = word_series[word_series['Sentiment'] == 'positive'].drop_duplicates(subset='Word')\n",
    "negative_unique_words = word_series[word_series['Sentiment'] == 'negative'].drop_duplicates(subset='Word')\n",
    "neutral_unique_words = word_series[word_series['Sentiment'] == 'neutral'].drop_duplicates(subset='Word')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RBPqfy85i2wd"
   },
   "outputs": [],
   "source": [
    "word_series = pd.concat([word_series, positive_unique_words, negative_unique_words, neutral_unique_words], ignore_index=True)\n",
    "word_series = word_series.drop_duplicates(subset='Word')\n",
    "word_series.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aKa8AB98i6SC"
   },
   "outputs": [],
   "source": [
    "sentiment_counts = word_series['Sentiment'].value_counts()\n",
    "print(sentiment_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dNCC1s2Li9TF"
   },
   "outputs": [],
   "source": [
    "word_series = word_series[word_series['Sentiment'] != 'neutral']\n",
    "word_series.reset_index(drop=True, inplace=True)\n",
    "print(word_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3mUj8VJIm1Ta"
   },
   "source": [
    "# **Visualizing Word Clouds for different sentiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rOeQ07HtjAty"
   },
   "outputs": [],
   "source": [
    "# Visualizing Word Clouds for different sentiments\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U_hTDIMUjDtz"
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "word_series['Sentiment'] = label_encoder.fit_transform(word_series['Sentiment'])\n",
    "sentiments = word_series['Sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZnNtheLajHXU"
   },
   "outputs": [],
   "source": [
    "for sentiment in sentiments:\n",
    "    sentiment_words = word_series[word_series['Sentiment'] == sentiment]\n",
    "    text = ' '.join(sentiment_words['Word'])\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.title(f'Word Cloud for {label_encoder.inverse_transform([sentiment])[0]} Sentiment')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrc_vSmsm99j"
   },
   "source": [
    "# **Bag of Words (BOW) with one-hot encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vP3AFddNjLCm"
   },
   "outputs": [],
   "source": [
    "# Bag of Words (BOW) with one-hot encoding\n",
    "X = word_series['Word']\n",
    "y = word_series['Sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yPTuHrq9jS1t"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 4), max_features=500000, binary=True)\n",
    "vectorizer.fit(X_train)\n",
    "X_train_bow = vectorizer.transform(X_train)\n",
    "X_test_bow = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RyJsouKAjTQo"
   },
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train_bow, y_train)\n",
    "y_pred = logistic_model.predict(X_test_bow)\n",
    "report = classification_report(y_test, y_pred, zero_division=0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7t5ycR8XnD0O"
   },
   "source": [
    "# **Artificial Neural Network (ANN) with BOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gDvSxpbmjWCw"
   },
   "outputs": [],
   "source": [
    "# Artificial Neural Network (ANN) with BOW\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train_bow.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "y_train_binary = (y_train == 1).astype(int)\n",
    "y_test_binary = (y_test == 1).astype(int)\n",
    "\n",
    "model.fit(X_train_bow.toarray(), y_train_binary, epochs=5, batch_size=32, validation_split=0.2)\n",
    "\n",
    "y_pred_ann = (model.predict(X_test_bow.toarray()) > 0.5).astype(int)\n",
    "report_ann = classification_report(y_test_binary, y_pred_ann, zero_division=0)\n",
    "print(\"Classification Report - Artificial Neural Network:\\n\", report_ann)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2oBJe7SnJO7"
   },
   "source": [
    "# **TF-IDF with one-hot encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kiZf_Perjiy8"
   },
   "outputs": [],
   "source": [
    "# TF-IDF with one-hot encoding\n",
    "X = word_series['Word']\n",
    "y = word_series['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ycpt8c3ujlbp"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 4), max_features=500000, binary=True)\n",
    "tfidf_vectorizer.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "667eQ46mn33P"
   },
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf_vectorizer.transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g0ucuyncjomE"
   },
   "outputs": [],
   "source": [
    "logistic_model_tfidf = LogisticRegression()\n",
    "logistic_model_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf = logistic_model_tfidf.predict(X_test_tfidf)\n",
    "report_tfidf = classification_report(y_test, y_pred_tfidf, zero_division=0)\n",
    "print(report_tfidf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PEXvfzvnNhb"
   },
   "source": [
    "# **Artificial Neural Network (ANN) with TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lHAb4Rb2jwyZ"
   },
   "outputs": [],
   "source": [
    "# Artificial Neural Network (ANN) with TF-IDF\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_dim=X_train_tfidf.shape[1]),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "y_train_binary = (y_train == 1).astype(int)\n",
    "y_test_binary = (y_test == 1).astype(int)\n",
    "\n",
    "model.fit(X_train_tfidf.toarray(), y_train_binary, epochs=5, batch_size=32, validation_split=0.2)\n",
    "\n",
    "y_pred_ann = (model.predict(X_test_tfidf.toarray()) > 0.5).astype(int)\n",
    "report_ann = classification_report(y_test_binary, y_pred_ann, zero_division=0)\n",
    "print(\"Classification Report - Artificial Neural Network:\\n\", report_ann)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rc96fcECnR4L"
   },
   "source": [
    "# **Bigram with one-hot encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "unh2fOt5j0sw"
   },
   "outputs": [],
   "source": [
    "# Bigram with one-hot encoding\n",
    "X = word_series['Word']\n",
    "y = word_series['Sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eUssUb-cj4TT"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "count_vectorizer = CountVectorizer(ngram_range=(2, 2), max_features=500000, binary=True)\n",
    "X_train_bg = count_vectorizer.fit_transform(X_train)\n",
    "X_test_bg = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3TMqdWpsj7b4"
   },
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train_bg, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hNxBNhFTj-jN"
   },
   "outputs": [],
   "source": [
    "y_pred_bigram = logistic_model.predict(X_test_bg)\n",
    "report_bigram = classification_report(y_test, y_pred_bigram, zero_division=0)\n",
    "print(report_bigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvjYyG3mnWim"
   },
   "source": [
    "# **Artificial Neural Network (ANN) with Bigram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rsoUj4v2kHos"
   },
   "outputs": [],
   "source": [
    "# Artificial Neural Network (ANN) with Bigram\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train_bg.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "y_train_binary = (y_train == 1).astype(int)\n",
    "y_test_binary = (y_test == 1).astype(int)\n",
    "\n",
    "model.fit(X_train_bg.toarray(), y_train_binary, epochs=5, batch_size=32, validation_split=0.2)\n",
    "\n",
    "y_pred_ann = (model.predict(X_test_bg.toarray()) > 0.5).astype(int)\n",
    "report_ann = classification_report(y_test_binary, y_pred_ann, zero_division=0)\n",
    "print(\"Classification Report - Artificial Neural Network:\\n\", report_ann)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIEQwMQnnbCS"
   },
   "source": [
    "# **Confusion Matrix for BOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sWty0LvFkL4y"
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix for BOW\n",
    "confusion_bow = confusion_matrix(y_test_binary, y_pred_ann)\n",
    "class_names = ['Negative', 'Positive']\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_bow, annot=True, fmt='d', cmap='viridis', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - BOW')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXOiCy-Gngvx"
   },
   "source": [
    "# **Confusion Matrix for Bigram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OLS4SQ7pkO2k"
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix for Bigram\n",
    "confusion_bigram = confusion_matrix(y_test_binary, y_pred_bigram)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_bigram, annot=True, fmt='d', cmap='RdYlBu', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Bigram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GeJCumnlkSEZ"
   },
   "outputs": [],
   "source": [
    "print(\"Classification Report for BOW:\")\n",
    "print(report)\n",
    "\n",
    "print(\"\\nClassification Report for TF-IDF:\")\n",
    "print(report_tfidf)\n",
    "\n",
    "print(\"\\nClassification Report for Bigrams:\")\n",
    "print(report_bigram)\n",
    "\n",
    "print(word_series)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
